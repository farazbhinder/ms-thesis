\chapter{Introduction} \label{the-chapter-1}
\section{Motivation}
In most Information Extraction tasks, the first step is that of Named Entity Recognition \cite{DBLP:books/lib/JurafskyM09}. It deals with the extraction of named entities, such as names of persons, locations and organizations. The named entities occur frequently with events and time references, especially in documents belonging to the news domain. The terms in text that refer to absolute points in time, relative times or durations are called temporal expressions \cite{DBLP:books/lib/JurafskyM09}. The extraction of temporal expressions and events, in addition to the extraction of named entities can enable us to extract relations between entities and events to make information extraction more rich temporally. For instance, in the text ``Saarland University was established in 1948.", if temporal expression ``1948" is extracted, in addition to the entity ``Saarland Universiy" and the relation ``established"; this fact can be learned.

Temporal tagging is one of the sub tasks of Information Extraction; and has two steps, i.e., extraction and normalization of temporal expressions. The original focus of temporal tagging was news domain in its beginning \cite{DBLP:series/synthesis/2016Strotgen}, and most research has focused on processing English text documents till most recently \cite{DBLP:phd/de/Strotgen15}. Temporal tagging can be of great use in this age of smart-phones and influx of data; some potential application areas which can benefit from temporal tagging are:

\begin{itemize}
	\item \textbf{Information Retrieval:} One way to improve information retrieval for temporal needs is to take into account the temporal content in documents for ranking; for instance, Tiwiki \cite{DBLP:conf/www/AgarwalS17} is one such time-aware search engine for Wikipedia.  
	\item \textbf{Information Extraction:} Knowledge bases such as YAGO2 \cite{DBLP:journals/ai/HoffartSBW13} can benefit by extracting temporal scope with facts that have them; for instance, ``Jacques Chirac'' \texttt{holdsPoliticalPosition} ``President of France'' with temporal scope 1995-2007 \cite{DBLP:conf/www/KuzeyW12}. 
	\item \textbf{Personal Assistants:} In recent years, many personal assistants, such as Siri\footnote{\url{https://www.apple.com/ios/siri/}}, Cortana\footnote{\url{https://www.microsoft.com/en-us/windows/cortana}} and Alexa\footnote{\url{https://www.amazon.com/meet-alexa/b?ie=UTF8&node=16067214011}} have emerged on the scene to help users to search web, set reminders and manage calenders. These assistants can be synced to personal calender and email, that allows them to extract out events such as meeting reminders or a package delivery date from emails and add them to calender of user automatically. Many of these personal assistants are regularly updated to support further languages, in addition to English.
\end{itemize}

As mentioned earlier, until recently, most of the research on temporal tagging focuses on English language or a handful of other languages. The usual approaches of porting taggers from one language to another were difficult and often resulted in lower tagging quality \cite{DBLP:phd/de/Strotgen15}. HeidelTime\footnote{\url{https://github.com/HeidelTime/heideltime}} is a publicly available temporal tagger that has strict separation between algorithmic part and resources, that allows for easy adding of new modules to extend it for more languages \cite{DBLP:phd/de/Strotgen15}. At present, as of version 2.2.1, researchers have made available manual resources for 13 languages, such as Arabic \cite{strotgen2014time}, Croatian \cite{skukan2014heideltime} and French \cite{moriceau2013french}. Furthermore, Str{\"{o}}tgen and Gertz  in \cite{DBLP:conf/emnlp/StrotgenG15} made automatically developed resources for over 200 languages. 

The automatically developed resources of HeidelTime have shown promising results. For instance, on FR-TimeBank, a French temporal corpus, the F1 score for extraction phase using automatically developed resources was 70.8 compared to 91.0 when using the manually developed resources; the F1 score for normalization phase using automatically developed resources was 54.6 versus 73.6 when using the manually developed resources \cite{DBLP:conf/emnlp/StrotgenG15}. However, it was further shown in \cite{DBLP:conf/emnlp/StrotgenG15}, that the recall for couple of the languages evaluated using these automatically developed resources was lower in general. 

As mentioned earlier, HeidelTime has automatically developed resources for over 200 languages. These automatically developed resources can be used as baseline to tag documents temporally in over 200 languages; furthermore, these resources can also act as a starting point to extend them into manual ones \cite{DBLP:conf/emnlp/StrotgenG15}. Our goal, in this thesis is to improve the baseline quality of tagging using the automatically developed resources. To achieve our goal, we have identified three areas to improve automatically developed resources in: i) make them better for morphologically rich languages. ii) make them better for unsegmented languages. iii) make them better in general by learning frequently occurring temporal expressions as language-specific rules.  Furthermore, we aim to do detailed analysis using various corpora and Wikipedia dumps\footnote{\url{https://dumps.wikimedia.org/}}.

\section{Problem Statement}
While temporal tagging is an active research problem for English, very few systems have support for many languages. HeidelTime is a truly multilingual temporal tagger that supports over 200 languages using the automatically developed resources. Str{\"{o}}tgen and Gertz in \cite{DBLP:conf/emnlp/StrotgenG15} explain how the automatically developed resources were realized for HeidelTime. These automatically developed resources, while providing baseline temporal tagger for many languages for the first time, have following shortcomings:
\begin{itemize}
	\item \textbf{Disregards inflection:} A major issue with automatically developed resources of HeidelTime is that the morphological changes of words, i.e., inflections, are not covered.
	\item \textbf{Ignores unsegmented languages:} The automatically developed resources have same rules for all languages and these rules use a space to join individual patterns in rules. As unsegmented languages do not use space as delimeter, so automatically developed resources perform poorly on such languages. 
	\item \textbf{No language-specific rules:} The automatically developed resources, as they use same rules for all languages, ignore the intricacies of different languages and how temporal expressions might appear in them. 
	\item \textbf{Evaluating languages that lacked corpora:} The authors in \cite{DBLP:conf/emnlp/StrotgenG15} evaluated automatically developed resources for languages that had temporally annotated corpora available, it is obviously hard to evaluate the languages that have no corpora available. 
\end{itemize}

\section{Contributions}
The contribution of this thesis is creation of new automatically developed resources for HeidelTime, making the following improvements to the previous version:
\begin{itemize}
	\item We enhance the automatically developed resources to accommodate morphologically rich languages.
	\item We adjust the automatically developed resources to accommodate unsegmented languages.
	\item We enhance the automatically developed resources for all languages by learning frequently occurring temporal language specific temporal patterns as rules.
	\item We run detailed evaluations and analysis, i.e., evaluations on available temporally annotated corpora and analysis using Wikipedia dumps for other languages.
\end{itemize}
\section{Outline}
The remainder of this thesis is organized as follows: In Chapter \ref{the-chapter-2}, we explain some basic concepts and discuss the related work. In Chapter \ref{the-chapter-3}, we discuss the HeidelTime and its multilingual model. In Chapter \ref{the-chapter-4}, we describe our implementation of improved HeidelTime multilingual  model. In Chapter \ref{the-chapter-5}, we present in detail the evaluations and our findings. Finally, in Chapter \ref{the-chapter-6}, we give conclusion and list future directions.